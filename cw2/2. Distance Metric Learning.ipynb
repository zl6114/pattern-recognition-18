{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Metric Learning\n",
    "\n",
    "## Utilities and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python Version: {}'.format( python_version() ) )\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm_notebook # Progress bar\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from   scipy.io import loadmat\n",
    "\n",
    "# sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors     import KNeighborsClassifier\n",
    "from sklearn.neighbors     import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (14096, 2048)\n",
      "Loading Training indexes : (7368,)\n",
      "Loading Query indexes : (1400,)\n",
      "Loading Gallery indexes : (5328,)\n"
     ]
    }
   ],
   "source": [
    "with open( \"PR_data/feature_data.json\", \"r\" ) as file:\n",
    "    features = json.load( file )\n",
    "    \n",
    "data = np.asarray( features )\n",
    "\n",
    "print( 'Data shape: {}'.format( data.shape ) )\n",
    "\n",
    "# Load matfile\n",
    "mat = loadmat( 'PR_data/cuhk03_new_protocol_config_labeled.mat' )\n",
    "\n",
    "# Load labels\n",
    "labels = mat[ 'labels' ].flatten()\n",
    "\n",
    "# Load camId\n",
    "camIds = mat[ 'camId' ].flatten()\n",
    "\n",
    "# Load indexes\n",
    "train_idxs   = mat[ 'train_idx' ].flatten()\n",
    "query_idxs    = mat[ 'query_idx' ].flatten()\n",
    "gallery_idxs = mat[ 'gallery_idx' ].flatten()\n",
    "\n",
    "# Load training indexes\n",
    "print( \"Loading Training indexes : {}\".format( train_idxs.shape ) )\n",
    "print( \"Loading Query indexes : {}\".format( query_idxs.shape ) )\n",
    "print( \"Loading Gallery indexes : {}\".format( gallery_idxs.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train/Query/Gallery Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (7368, 2048)\n",
      "Train Label : (7368,)\n",
      "\n",
      "Query Set : (1400, 2048)\n",
      "Query Label : (1400,)\n",
      "Query CamId : (1400,)\n",
      "\n",
      "Gallery Set : (5328, 2048)\n",
      "Gallery Label : (5328,)\n",
      "Gallery CamId : (5328,)\n"
     ]
    }
   ],
   "source": [
    "# Create Train Set\n",
    "train_set   = []\n",
    "train_label = []\n",
    "\n",
    "for i in train_idxs:\n",
    "    train_set.append( data[ i - 1 ] )\n",
    "    train_label.append( labels[ i - 1 ] )\n",
    "    \n",
    "train_set   = np.asarray( train_set )\n",
    "train_label = np.asarray( train_label )\n",
    "\n",
    "print( 'Train Set : {}'.format( train_set.shape ) )\n",
    "print( 'Train Label : {}'.format( train_label.shape ) )\n",
    "\n",
    "\n",
    "# Create Query Set\n",
    "query_set   = []\n",
    "query_label = []\n",
    "query_camId = []\n",
    "\n",
    "for i in query_idxs:\n",
    "    query_set.append( data[ i - 1] )\n",
    "    query_label.append( labels[ i - 1 ] )\n",
    "    query_camId.append( camIds[ i - 1 ] )\n",
    "    \n",
    "query_set   = np.asarray( query_set )\n",
    "query_label = np.asarray( query_label )\n",
    "query_camId = np.asarray( query_camId )\n",
    "\n",
    "print( '\\nQuery Set : {}'.format( query_set.shape ) )\n",
    "print( 'Query Label : {}'.format( query_label.shape ) )\n",
    "print( 'Query CamId : {}'.format( query_camId.shape ) )\n",
    "\n",
    "\n",
    "# Create Gallery Set\n",
    "gallery_set   = []\n",
    "gallery_label = []\n",
    "gallery_camId = []\n",
    "\n",
    "for i in gallery_idxs:\n",
    "    gallery_set.append( data[ i - 1] )\n",
    "    gallery_label.append( labels[ i - 1 ] )\n",
    "    gallery_camId.append( camIds[ i - 1 ] )\n",
    "    \n",
    "gallery_set   = np.asarray( gallery_set )\n",
    "gallery_label = np.asarray( gallery_label )\n",
    "gallery_camId = np.asarray( gallery_camId )\n",
    "\n",
    "print( '\\nGallery Set : {}'.format( gallery_set.shape ) )\n",
    "print( 'Gallery Label : {}'.format( gallery_label.shape ) )\n",
    "print( 'Gallery CamId : {}'.format( gallery_camId.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "* Pick 100 random identites from the training set\n",
    "* Remove all data with those 100 identities from training set and put in validation set\n",
    "\n",
    "There exists an idea in Computer Vision that you use validation set only to specify the number of iterations that is optimal for your design and then you include your validation set into train set and perform final training (without validation set) for this fixed amount of iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting *100* Random Identities For Validation Set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14996a87f13e44efbb9990d08b4cb2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set with Validation removed: (6399, 2049)\n",
      "Validation Set: (970, 2049) ( Has an extra row due to np.zeros )\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_unique_labels = np.unique( train_label )\n",
    "\n",
    "# Select 100 Random Identities\n",
    "shuffled_validation_labels = shuffle( train_unique_labels, random_state = RANDOM_STATE )[ : 100 ] \n",
    "print( 'Selecting *{}* Random Identities For Validation Set'.format( shuffled_validation_labels.shape[ 0 ] ) )\n",
    "\n",
    "train_validate = np.zeros( ( 1, 2049 ) )\n",
    "train_set_validate_removed = np.vstack( ( train_set.T, train_label ) ).T\n",
    "\n",
    "for identity in tqdm_notebook( shuffled_validation_labels ):\n",
    "    \n",
    "    # Go through data and remove rows with that identity\n",
    "    validation = train_set_validate_removed[ np.where( train_set_validate_removed[ :, -1 ] == identity ) ]\n",
    "    \n",
    "    train_validate = np.vstack( ( train_validate, validation ) )\n",
    "    \n",
    "    train_set_validate_removed = train_set_validate_removed[ np.where( train_set_validate_removed[ :, -1 ] != identity )]\n",
    "    \n",
    "print( 'Training Set with Validation removed: {}'.format( train_set_validate_removed.shape ) )\n",
    "print( 'Validation Set: {} ( Has an extra row due to np.zeros )'.format( train_validate.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train Set: (6399, 2048) \n",
      "Train Labels: (6399, 1)\n",
      "CV Validation Set: (969, 2048) \n",
      "Validation Labels: (969, 1)\n"
     ]
    }
   ],
   "source": [
    "cv_train_set   = train_set_validate_removed.T[ : -1 ].T\n",
    "cv_train_label = train_set_validate_removed.T[ -1 : ].T\n",
    "\n",
    "cv_validation_set = train_validate.T[ : -1 ].T[ 1: ]\n",
    "cv_validation_label = train_validate.T[ -1 : ].T[ 1 : ]\n",
    "\n",
    "print( 'CV Train Set: {} \\nTrain Labels: {}'.format( cv_train_set.shape, cv_train_label.shape ) )\n",
    "print( 'CV Validation Set: {} \\nValidation Labels: {}'.format( cv_validation_set.shape, cv_validation_label.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanobis\n",
    "\n",
    "### Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7368, 7368)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.dot( train_set, train_set.T )\n",
    "\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w, v = np.linalg.eig( S )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.dot( np.diag( np.sqrt( w ) ), v.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7368, 7368)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = np.linalg.inv( np.dot( train_set.T, train_set ) )\n",
    "\n",
    "w2, v2 = np.linalg.eig( S2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = np.dot( np.diag( np.sqrt( w2 ) ), v2.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 1400)\n",
      "(2048, 5328)\n"
     ]
    }
   ],
   "source": [
    "qs = np.dot( G2.T, query_set.T )\n",
    "gs = np.dot( G2.T, gallery_set.T )\n",
    "\n",
    "print( qs.shape )\n",
    "print( gs.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 2050)\n",
      "Gallery Augmented: (5328, 2050)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( n_neighbors = knn_n_neighbors, metric = knn_metric )\n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e03b729b334ae08a8662bf4f8a7970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 46.57142857142857%\n",
      "rank@5: 65.64285714285715%\n",
      "rank@10: 74.35714285714286%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=110, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCA = PCA( n_components = 110, whiten = True )\n",
    "PCA.fit( train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_set = PCA.transform( train_set )\n",
    "pca_gallery_set = PCA.transform( gallery_set )\n",
    "pca_query_set = PCA.transform( query_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit( pca_train_set, train_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_train_set = lda.transform( pca_train_set )\n",
    "lda_gallery_set = lda.transform( pca_gallery_set )\n",
    "lda_query_set = lda.transform( pca_query_set )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## LMNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aufar/py_36_env/lib/python3.6/site-packages/metric_learn/lmnn.py:62: UserWarning: use_pca does nothing for the python_LMNN implementation\n",
      "  warnings.warn('use_pca does nothing for the python_LMNN implementation')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2680791.7849133373 -327865.8640466016 32 1.0099999999999999e-06\n",
      "3 2373417.7525565587 -307374.0323567786 22 1.0200999999999998e-06\n",
      "4 2082377.8480223005 -291039.9045342582 15 1.0303009999999997e-06\n",
      "5 1808155.1803297447 -274222.6676925558 12 1.0406040099999998e-06\n",
      "6 1551203.988358576 -256951.19197116862 12 1.0510100500999999e-06\n",
      "7 1312076.9391843034 -239127.0491742727 11 1.061520150601e-06\n",
      "8 1091364.1519528725 -220712.78723143088 12 1.07213535210701e-06\n",
      "9 889664.4418852046 -201699.71006766788 11 1.08285670562808e-06\n",
      "10 707596.0949832664 -182068.3469019382 11 1.0936852726843608e-06\n",
      "11 545787.6503094791 -161808.44467378734 10 1.1046221254112045e-06\n",
      "12 404885.95367982704 -140901.69662965205 10 1.1156683466653166e-06\n",
      "13 285551.8507404328 -119334.10293939424 10 1.1268250301319698e-06\n",
      "14 188463.36441767536 -97088.48632275744 8 1.1380932804332895e-06\n",
      "15 114314.39407013908 -74148.97034753628 10 1.1494742132376223e-06\n",
      "16 63812.82782729218 -50501.5662428469 10 1.1609689553699985e-06\n",
      "17 37689.16050548293 -26123.667321809255 31 1.1725786449236986e-06\n",
      "18 34259.07517657448 -3430.085328908448 195 5.921522156864678e-07\n",
      "19 34259.07517657448 0.0 195 2.124784749367352e-21\n",
      "20 34259.07517657448 0.0 195 2.6825407460762816e-22\n",
      "21 34259.07517657448 0.0 195 2.7093661535370446e-22\n",
      "LMNN converged with objective 34259.07517657448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "python_LMNN(convergence_tol=0.001, k=5, learn_rate=1e-06, max_iter=200,\n",
       "      min_iter=20, regularization=0.5, use_pca=True, verbose=True)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metric_learn import LMNN\n",
    "\n",
    "lmnn = LMNN( k = 5, min_iter = 20, max_iter = 200, learn_rate = 1e-6, verbose = True  )\n",
    "lmnn.fit( lda_train_set, train_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_euclidean( x1, x2 ):\n",
    "  \n",
    "    diff = np.subtract( x1, x2 )\n",
    "    return np.sum( np.dot( diff.T, diff ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 112)\n",
      "Gallery Augmented: (5328, 112)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "qs = lmnn.transform( lda_query_set ).T\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "gs = lmnn.transform( lda_gallery_set ).T\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30,\n",
       "         metric=<function square_euclidean at 0x7f9176b897b8>,\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( algorithm = 'ball_tree',\n",
    "                       n_neighbors = knn_n_neighbors,\n",
    "                       metric = square_euclidean )\n",
    "                       \n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2572184fb86644bca5ce43a2f656f155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 39.0%\n",
      "rank@5: 58.857142857142854%\n",
      "rank@10: 66.64285714285715%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY:\n",
    "\n",
    "* Kernel PCA with non linear kernels ( RBF? )\n",
    "* Stacked with LMNN ( since we now in higher dimension )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NCA]\n",
      "[NCA]  Iteration      Objective Value    Time(s)\n",
      "[NCA] ------------------------------------------\n",
      "[NCA]          0         7.366959e+03      20.74\n",
      "[NCA]          1         7.367001e+03      20.57\n",
      "[NCA]          2         7.367999e+03      21.05\n",
      "[NCA]          3         7.368000e+03      20.63\n",
      "[NCA]          4         7.368000e+03      21.33\n",
      "[NCA] Training took   108.03s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NCA(learning_rate='deprecated', max_iter=100, num_dims=None, tol=None,\n",
       "  verbose=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metric_learn import NCA\n",
    "\n",
    "nca = NCA( max_iter = 100, verbose = True )\n",
    "nca.fit( train_set, train_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nca_train_set = nca.transform( train_set )\n",
    "nca_gallery_set = nca.transform( gallery_set )\n",
    "nca_query_set = nca.transform( query_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 2050)\n",
      "Gallery Augmented: (5328, 2050)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "qs = nca_query_set.T\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "gs = nca_gallery_set.T\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( algorithm = 'ball_tree',\n",
    "                       n_neighbors = knn_n_neighbors,\n",
    "                       metric = knn_metric )\n",
    "                       \n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a9ec4a15494a5991bbe33b121f3291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 44.642857142857146%\n",
      "rank@5: 65.92857142857143%\n",
      "rank@10: 73.85714285714286%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA (Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=None, kernel='cosine',\n",
       "     kernel_params=None, max_iter=None, n_components=1000, n_jobs=None,\n",
       "     random_state=None, remove_zero_eig=False, tol=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "KPCA = KernelPCA( n_components = 1000, kernel = 'cosine' )\n",
    "KPCA.fit( train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_train_set = KPCA.transform( train_set )\n",
    "kpca_gallery_set = KPCA.transform( gallery_set )\n",
    "kpca_query_set = KPCA.transform( query_set )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 1002)\n",
      "Gallery Augmented: (5328, 1002)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "qs = kpca_query_set.T\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "gs = kpca_gallery_set.T\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( algorithm = 'ball_tree',\n",
    "                       n_neighbors = knn_n_neighbors,\n",
    "                       metric = knn_metric )\n",
    "                       \n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d21d98f1ed243dc85d8d0f2a039da2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 47.35714285714286%\n",
      "rank@5: 67.14285714285714%\n",
      "rank@10: 75.07142857142857%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NCA]\n",
      "[NCA]  Iteration      Objective Value    Time(s)\n",
      "[NCA] ------------------------------------------\n",
      "[NCA]          0         7.364199e+03      11.53\n",
      "[NCA]          1         7.366398e+03      11.41\n",
      "[NCA]          2         7.367468e+03      11.36\n",
      "[NCA]          3         7.367879e+03      11.37\n",
      "[NCA]          4         7.367897e+03      11.38\n",
      "[NCA]          5         7.367952e+03      11.37\n",
      "[NCA]          6         7.367973e+03      11.37\n",
      "[NCA]          7         7.367987e+03      11.31\n",
      "[NCA]          8         7.367993e+03      11.33\n",
      "[NCA]          9         7.367997e+03      11.27\n",
      "[NCA]         10         7.367998e+03      11.34\n",
      "[NCA]         11         7.367999e+03      11.32\n",
      "[NCA]         12         7.368000e+03      11.26\n",
      "[NCA]         13         7.368000e+03      11.30\n",
      "[NCA]         14         7.368000e+03      11.31\n",
      "[NCA]         15         7.368000e+03      11.37\n",
      "[NCA] Training took   185.01s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NCA(learning_rate='deprecated', max_iter=100, num_dims=None, tol=None,\n",
       "  verbose=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metric_learn import NCA\n",
    "\n",
    "nca = NCA( max_iter = 100, verbose = True )\n",
    "nca.fit( kpca_train_set, train_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nca_train_set = nca.transform( kpca_train_set )\n",
    "nca_gallery_set = nca.transform( kpca_gallery_set )\n",
    "nca_query_set = nca.transform( kpca_query_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 1002)\n",
      "Gallery Augmented: (5328, 1002)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "qs = nca_query_set.T\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "gs = nca_gallery_set.T\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( algorithm = 'ball_tree',\n",
    "                       n_neighbors = knn_n_neighbors,\n",
    "                       metric = knn_metric )\n",
    "                       \n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62523777f3e4b5790518fcfbddded0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 43.642857142857146%\n",
      "rank@5: 63.714285714285715%\n",
      "rank@10: 71.5%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | rank@1 | rank@5 | rank@10 |\n",
    "| --- | --- | --- | --- |\n",
    "Baseline | 47.0% | 66.85714285714286% | 74.92857142857143%\n",
    "KPCA cosine ( 110 components )| 47.42857142857143% | 67.0% | 74.85714285714286%\n",
    "KPCA cosine 400 | 47.785714285714285% | 67.14285714285714% | 75.0%\n",
    "KPCA cosine 1000 | 47.35714285714286% | 67.14285714285714% | 75.07142857142857%\n",
    "NCA | 44.642857142857146% | 65.92857142857143% | 73.85714285714286%\n",
    "KPCA cosine ( 100 ) + NCA | 45.42857142857143 | 66.21428571428571 | 75.35714285714286\n",
    "kpca cosine 400 + NCA | 46.42857142857143% | 67.28571428571428% | 74.57142857142857%\n",
    "kpca cosine 1000 + NCA | 43.642857142857146% | 63.714285714285715% | 71.5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
