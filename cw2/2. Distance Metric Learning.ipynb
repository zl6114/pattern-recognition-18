{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Metric Learning\n",
    "\n",
    "To run each distance metric learning method, run all the cells in that section\n",
    "\n",
    "## Utilities and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python Version: {}'.format( python_version() ) )\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm_notebook # Progress bar\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from   scipy.io import loadmat\n",
    "\n",
    "# sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors     import KNeighborsClassifier\n",
    "from sklearn.neighbors     import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (14096, 2048)\n",
      "Loading Training indexes : (7368,)\n",
      "Loading Query indexes : (1400,)\n",
      "Loading Gallery indexes : (5328,)\n"
     ]
    }
   ],
   "source": [
    "with open( \"PR_data/feature_data.json\", \"r\" ) as file:\n",
    "    features = json.load( file )\n",
    "    \n",
    "data = np.asarray( features )\n",
    "\n",
    "print( 'Data shape: {}'.format( data.shape ) )\n",
    "\n",
    "# Load matfile\n",
    "mat = loadmat( 'PR_data/cuhk03_new_protocol_config_labeled.mat' )\n",
    "\n",
    "# Load labels\n",
    "labels = mat[ 'labels' ].flatten()\n",
    "\n",
    "# Load camId\n",
    "camIds = mat[ 'camId' ].flatten()\n",
    "\n",
    "# Load indexes\n",
    "train_idxs   = mat[ 'train_idx' ].flatten()\n",
    "query_idxs    = mat[ 'query_idx' ].flatten()\n",
    "gallery_idxs = mat[ 'gallery_idx' ].flatten()\n",
    "\n",
    "# Load training indexes\n",
    "print( \"Loading Training indexes : {}\".format( train_idxs.shape ) )\n",
    "print( \"Loading Query indexes : {}\".format( query_idxs.shape ) )\n",
    "print( \"Loading Gallery indexes : {}\".format( gallery_idxs.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train/Query/Gallery Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (7368, 2048)\n",
      "Train Label : (7368,)\n",
      "\n",
      "Query Set : (1400, 2048)\n",
      "Query Label : (1400,)\n",
      "Query CamId : (1400,)\n",
      "\n",
      "Gallery Set : (5328, 2048)\n",
      "Gallery Label : (5328,)\n",
      "Gallery CamId : (5328,)\n"
     ]
    }
   ],
   "source": [
    "def generateSets():\n",
    "    # Create Train Set\n",
    "    train_set   = []\n",
    "    train_label = []\n",
    "\n",
    "    for i in train_idxs:\n",
    "        train_set.append( data[ i - 1 ] )\n",
    "        train_label.append( labels[ i - 1 ] )\n",
    "\n",
    "    train_set   = np.asarray( train_set )\n",
    "    train_label = np.asarray( train_label )\n",
    "\n",
    "    print( 'Train Set : {}'.format( train_set.shape ) )\n",
    "    print( 'Train Label : {}'.format( train_label.shape ) ) \n",
    "\n",
    "    # Create Query Set\n",
    "    query_set   = []\n",
    "    query_label = []\n",
    "    query_camId = []\n",
    "\n",
    "    for i in query_idxs:\n",
    "        query_set.append( data[ i - 1] )\n",
    "        query_label.append( labels[ i - 1 ] )\n",
    "        query_camId.append( camIds[ i - 1 ] )\n",
    "\n",
    "    query_set   = np.asarray( query_set )\n",
    "    query_label = np.asarray( query_label )\n",
    "    query_camId = np.asarray( query_camId )\n",
    "\n",
    "    print( '\\nQuery Set : {}'.format( query_set.shape ) )\n",
    "    print( 'Query Label : {}'.format( query_label.shape ) )\n",
    "    print( 'Query CamId : {}'.format( query_camId.shape ) )\n",
    "\n",
    "\n",
    "    # Create Gallery Set\n",
    "    gallery_set   = []\n",
    "    gallery_label = []\n",
    "    gallery_camId = []\n",
    "\n",
    "    for i in gallery_idxs:\n",
    "        gallery_set.append( data[ i - 1] )\n",
    "        gallery_label.append( labels[ i - 1 ] )\n",
    "        gallery_camId.append( camIds[ i - 1 ] )\n",
    "\n",
    "    gallery_set   = np.asarray( gallery_set )\n",
    "    gallery_label = np.asarray( gallery_label )\n",
    "    gallery_camId = np.asarray( gallery_camId )\n",
    "\n",
    "    print( '\\nGallery Set : {}'.format( gallery_set.shape ) )\n",
    "    print( 'Gallery Label : {}'.format( gallery_label.shape ) )\n",
    "    print( 'Gallery CamId : {}'.format( gallery_camId.shape ) )\n",
    "    \n",
    "    return train_set, train_label, query_set, query_label, query_camId, gallery_set, gallery_label, gallery_camId\n",
    "    \n",
    "train_set, train_label, query_set, query_label, query_camId, gallery_set, gallery_label, gallery_camId = generateSets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "* Pick 100 random identites from the training set\n",
    "* Remove all data with those 100 identities from training set and put in validation set\n",
    "\n",
    "There exists an idea in Computer Vision that you use validation set only to specify the number of iterations that is optimal for your design and then you include your validation set into train set and perform final training (without validation set) for this fixed amount of iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting *100* Random Identities For Validation Set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef18dd1380f74031a3a541be60ee119a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set with Validation removed: (6399, 2049)\n",
      "Validation Set: (970, 2049) ( Has an extra row due to np.zeros )\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_unique_labels = np.unique( train_label )\n",
    "\n",
    "# Select 100 Random Identities\n",
    "shuffled_validation_labels = shuffle( train_unique_labels, random_state = RANDOM_STATE )[ : 100 ] \n",
    "print( 'Selecting *{}* Random Identities For Validation Set'.format( shuffled_validation_labels.shape[ 0 ] ) )\n",
    "\n",
    "train_validate = np.zeros( ( 1, 2049 ) )\n",
    "train_set_validate_removed = np.vstack( ( train_set.T, train_label ) ).T\n",
    "\n",
    "for identity in tqdm_notebook( shuffled_validation_labels ):\n",
    "    \n",
    "    # Go through data and remove rows with that identity\n",
    "    validation = train_set_validate_removed[ np.where( train_set_validate_removed[ :, -1 ] == identity ) ]\n",
    "    \n",
    "    train_validate = np.vstack( ( train_validate, validation ) )\n",
    "    \n",
    "    train_set_validate_removed = train_set_validate_removed[ np.where( train_set_validate_removed[ :, -1 ] != identity )]\n",
    "    \n",
    "print( 'Training Set with Validation removed: {}'.format( train_set_validate_removed.shape ) )\n",
    "print( 'Validation Set: {} ( Has an extra row due to np.zeros )'.format( train_validate.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Train Set: (6399, 2048) \n",
      "Train Labels: (6399, 1)\n",
      "CV Validation Set: (969, 2048) \n",
      "Validation Labels: (969, 1)\n"
     ]
    }
   ],
   "source": [
    "cv_train_set   = train_set_validate_removed.T[ : -1 ].T\n",
    "cv_train_label = train_set_validate_removed.T[ -1 : ].T\n",
    "\n",
    "cv_validation_set = train_validate.T[ : -1 ].T[ 1: ]\n",
    "cv_validation_label = train_validate.T[ -1 : ].T[ 1 : ]\n",
    "\n",
    "print( 'CV Train Set: {} \\nTrain Labels: {}'.format( cv_train_set.shape, cv_train_label.shape ) )\n",
    "print( 'CV Validation Set: {} \\nValidation Labels: {}'.format( cv_validation_set.shape, cv_validation_label.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Mahalanobis\n",
    "\n",
    "### Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = np.linalg.inv( np.dot( train_set.T, train_set ) )\n",
    "\n",
    "w2, v2 = np.linalg.eig( S2 )\n",
    "\n",
    "G2 = np.dot( np.diag( np.sqrt( w2 ) ), v2.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 1400)\n",
      "(2048, 5328)\n"
     ]
    }
   ],
   "source": [
    "qs = np.dot( G2.T, query_set.T )\n",
    "gs = np.dot( G2.T, gallery_set.T )\n",
    "\n",
    "print( qs.shape )\n",
    "print( gs.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 2050)\n",
      "Gallery Augmented: (5328, 2050)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( n_neighbors = knn_n_neighbors, metric = knn_metric )\n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bac224edc1241c59e39f8d39c2cdef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 46.57142857142857%\n",
      "rank@2: 54.42857142857142%\n",
      "rank@3: 59.21428571428572%\n",
      "rank@4: 62.5%\n",
      "rank@5: 65.64285714285715%\n",
      "rank@6: 67.71428571428572%\n",
      "rank@7: 69.71428571428572%\n",
      "rank@8: 71.64285714285714%\n",
      "rank@9: 73.35714285714286%\n",
      "rank@10: 74.35714285714286%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt2  = query_rank_list.T[ : 2 ].T\n",
    "rankAt3 = query_rank_list.T[ : 3 ].T\n",
    "rankAt4  = query_rank_list.T[ : 4 ].T\n",
    "rankAt5 = query_rank_list.T[ : 5 ].T\n",
    "rankAt6  = query_rank_list.T[ : 6 ].T\n",
    "rankAt7  = query_rank_list.T[ : 7 ].T\n",
    "rankAt8 = query_rank_list.T[ : 8 ].T\n",
    "rankAt9  = query_rank_list.T[ : 9 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc2  = np.sum( rankAt2, axis = 1 ) > 0 \n",
    "cmc3  = np.sum( rankAt3, axis = 1 ) > 0 \n",
    "cmc4  = np.sum( rankAt4, axis = 1 ) > 0 \n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc6  = np.sum( rankAt6, axis = 1 ) > 0 \n",
    "cmc7  = np.sum( rankAt7, axis = 1 ) > 0\n",
    "cmc8  = np.sum( rankAt8, axis = 1 ) > 0 \n",
    "cmc9  = np.sum( rankAt9, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "a11 = np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100\n",
    "a21 = np.sum( cmc2 ) / cmc2.shape[ 0 ] * 100\n",
    "a31 = np.sum( cmc3 ) / cmc3.shape[ 0 ] * 100\n",
    "a41 = np.sum( cmc4 ) / cmc4.shape[ 0 ] * 100\n",
    "a51 = np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100\n",
    "a61 = np.sum( cmc6 ) / cmc6.shape[ 0 ] * 100\n",
    "a71 = np.sum( cmc7 ) / cmc7.shape[ 0 ] * 100\n",
    "a81 = np.sum( cmc8 ) / cmc8.shape[ 0 ] * 100\n",
    "a91 = np.sum( cmc9 ) / cmc9.shape[ 0 ] * 100\n",
    "a101 = np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@2: {}%'.format( np.sum( cmc2 ) / cmc2.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@3: {}%'.format( np.sum( cmc3 ) / cmc3.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@4: {}%'.format( np.sum( cmc4 ) / cmc4.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@6: {}%'.format( np.sum( cmc6 ) / cmc6.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@7: {}%'.format( np.sum( cmc7 ) / cmc7.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@8: {}%'.format( np.sum( cmc8 ) / cmc8.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@9: {}%'.format( np.sum( cmc9 ) / cmc9.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (7368, 2048)\n",
      "Train Label : (7368,)\n",
      "\n",
      "Query Set : (1400, 2048)\n",
      "Query Label : (1400,)\n",
      "Query CamId : (1400,)\n",
      "\n",
      "Gallery Set : (5328, 2048)\n",
      "Gallery Label : (5328,)\n",
      "Gallery CamId : (5328,)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_label, query_set, query_label, query_camId, gallery_set, gallery_label, gallery_camId = generateSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=110, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCA = PCA( n_components = 110, whiten = False )\n",
    "PCA.fit( train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_set = PCA.transform( train_set )\n",
    "pca_gallery_set = PCA.transform( gallery_set )\n",
    "pca_query_set = PCA.transform( query_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 112)\n",
      "Gallery Augmented: (5328, 112)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "qs = pca_query_set.T\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "gs = pca_gallery_set.T\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( algorithm = 'ball_tree',\n",
    "                       n_neighbors = knn_n_neighbors,\n",
    "                       metric = knn_metric )\n",
    "                       \n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4510c219e8204b92ab264c2d41cf7242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 46.5%\n",
      "rank@5: 67.57142857142857%\n",
      "rank@10: 75.0%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Neighbourhood Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (7368, 2048)\n",
      "Train Label : (7368,)\n",
      "\n",
      "Query Set : (1400, 2048)\n",
      "Query Label : (1400,)\n",
      "Query CamId : (1400,)\n",
      "\n",
      "Gallery Set : (5328, 2048)\n",
      "Gallery Label : (5328,)\n",
      "Gallery CamId : (5328,)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_label, query_set, query_label, query_camId, gallery_set, gallery_label, gallery_camId = generateSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NCA]\n",
      "[NCA]  Iteration      Objective Value    Time(s)\n",
      "[NCA] ------------------------------------------\n",
      "[NCA]          0         7.366959e+03      30.17\n",
      "[NCA]          1         7.367001e+03      21.01\n",
      "[NCA]          2         7.367999e+03      20.25\n",
      "[NCA]          3         7.368000e+03      22.06\n",
      "[NCA]          4         7.368000e+03      20.31\n",
      "[NCA] Training took   117.81s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NCA(learning_rate='deprecated', max_iter=100, num_dims=None, tol=None,\n",
       "  verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metric_learn import NCA\n",
    "\n",
    "nca = NCA( max_iter = 100, verbose = True )\n",
    "nca.fit( train_set, train_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nca_train_set = nca.transform( train_set )\n",
    "nca_gallery_set = nca.transform( gallery_set )\n",
    "nca_query_set = nca.transform( query_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 2050)\n",
      "Gallery Augmented: (5328, 2050)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "qs = nca_query_set.T\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "gs = nca_gallery_set.T\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( algorithm = 'ball_tree',\n",
    "                       n_neighbors = knn_n_neighbors,\n",
    "                       metric = knn_metric )\n",
    "                       \n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e81523137f7470593f78dd43c216902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 44.642857142857146%\n",
      "rank@5: 65.92857142857143%\n",
      "rank@10: 73.85714285714286%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Kernel PCA (Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (7368, 2048)\n",
      "Train Label : (7368,)\n",
      "\n",
      "Query Set : (1400, 2048)\n",
      "Query Label : (1400,)\n",
      "Query CamId : (1400,)\n",
      "\n",
      "Gallery Set : (5328, 2048)\n",
      "Gallery Label : (5328,)\n",
      "Gallery CamId : (5328,)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_label, query_set, query_label, query_camId, gallery_set, gallery_label, gallery_camId = generateSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=None, kernel='cosine',\n",
       "     kernel_params=None, max_iter=None, n_components=200, n_jobs=None,\n",
       "     random_state=None, remove_zero_eig=False, tol=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "KPCA = KernelPCA( n_components = 200, kernel = 'cosine' )\n",
    "KPCA.fit( train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_train_set = KPCA.transform( train_set )\n",
    "kpca_gallery_set = KPCA.transform( gallery_set )\n",
    "kpca_query_set = KPCA.transform( query_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 202)\n",
      "Gallery Augmented: (5328, 202)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "qs = kpca_query_set.T\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "gs = kpca_gallery_set.T\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( algorithm = 'ball_tree',\n",
    "                       n_neighbors = knn_n_neighbors,\n",
    "                       metric = knn_metric )\n",
    "                       \n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bd9ef77626412d8e5ec08666b136d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 47.64285714285714%\n",
      "rank@5: 67.35714285714286%\n",
      "rank@10: 75.07142857142857%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Neighbourhood Component Analysis + KPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (7368, 2048)\n",
      "Train Label : (7368,)\n",
      "\n",
      "Query Set : (1400, 2048)\n",
      "Query Label : (1400,)\n",
      "Query CamId : (1400,)\n",
      "\n",
      "Gallery Set : (5328, 2048)\n",
      "Gallery Label : (5328,)\n",
      "Gallery CamId : (5328,)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_label, query_set, query_label, query_camId, gallery_set, gallery_label, gallery_camId = generateSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=None, kernel='cosine',\n",
       "     kernel_params=None, max_iter=None, n_components=200, n_jobs=None,\n",
       "     random_state=None, remove_zero_eig=False, tol=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "KPCA = KernelPCA( n_components = 200, kernel = 'cosine' )\n",
    "KPCA.fit( train_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_train_set = KPCA.transform( train_set )\n",
    "kpca_gallery_set = KPCA.transform( gallery_set )\n",
    "kpca_query_set = KPCA.transform( query_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NCA]\n",
      "[NCA]  Iteration      Objective Value    Time(s)\n",
      "[NCA] ------------------------------------------\n",
      "[NCA]          0         2.868342e+03       7.15\n",
      "[NCA]          1         3.606039e+03       7.05\n",
      "[NCA]          2         6.374301e+03       6.80\n",
      "[NCA]          3         7.358162e+03       6.41\n",
      "[NCA]          4         7.358533e+03       6.72\n",
      "[NCA]          5         7.359878e+03       6.71\n",
      "[NCA]          6         7.364979e+03       6.46\n",
      "[NCA]          7         7.367163e+03       6.36\n",
      "[NCA]          8         7.367437e+03       6.46\n",
      "[NCA]          9         7.367766e+03       6.43\n",
      "[NCA]         10         7.367882e+03       6.52\n",
      "[NCA]         11         7.367945e+03       6.47\n",
      "[NCA]         12         7.367974e+03       6.46\n",
      "[NCA]         13         7.367988e+03       6.49\n",
      "[NCA]         14         7.367994e+03       6.51\n",
      "[NCA]         15         7.367997e+03       6.44\n",
      "[NCA]         16         7.367999e+03       6.45\n",
      "[NCA]         17         7.367999e+03       6.49\n",
      "[NCA]         18         7.368000e+03       6.49\n",
      "[NCA]         19         7.368000e+03       6.47\n",
      "[NCA]         20         7.368000e+03       6.46\n",
      "[NCA]         21         7.368000e+03       6.47\n",
      "[NCA] Training took   146.58s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NCA(learning_rate='deprecated', max_iter=100, num_dims=None, tol=None,\n",
       "  verbose=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metric_learn import NCA\n",
    "\n",
    "nca = NCA( max_iter = 100, verbose = True )\n",
    "nca.fit( kpca_train_set, train_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nca_train_set = nca.transform( kpca_train_set )\n",
    "nca_gallery_set = nca.transform( kpca_gallery_set )\n",
    "nca_query_set = nca.transform( kpca_query_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (7368, 2048)\n",
      "Train Label : (7368,)\n",
      "\n",
      "Query Set : (1400, 2048)\n",
      "Query Label : (1400,)\n",
      "Query CamId : (1400,)\n",
      "\n",
      "Gallery Set : (5328, 2048)\n",
      "Gallery Label : (5328,)\n",
      "Gallery CamId : (5328,)\n"
     ]
    }
   ],
   "source": [
    "train_set, train_label, query_set, query_label, query_camId, gallery_set, gallery_label, gallery_camId = generateSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Augmented: (1400, 202)\n",
      "Gallery Augmented: (5328, 202)\n"
     ]
    }
   ],
   "source": [
    "# Query Augmented\n",
    "qs = nca_query_set.T\n",
    "\n",
    "query_augmented = np.vstack( ( qs, query_camId, query_label ) )\n",
    "query_augmented = query_augmented.T\n",
    "\n",
    "# Gallery Augmented\n",
    "gs = nca_gallery_set.T\n",
    "\n",
    "gallery_augmented = np.vstack( ( gs, gallery_camId, gallery_label ) )\n",
    "gallery_augmented = gallery_augmented.T\n",
    "\n",
    "print( 'Query Augmented: {}'.format( query_augmented.shape ) )\n",
    "print( 'Gallery Augmented: {}'.format( gallery_augmented.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='euclidean',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_n_neighbors = 20\n",
    "knn_metric = 'euclidean'\n",
    "\n",
    "KNN = NearestNeighbors( algorithm = 'ball_tree',\n",
    "                       n_neighbors = knn_n_neighbors,\n",
    "                       metric = knn_metric )\n",
    "                       \n",
    "KNN.fit( gallery_augmented[ :, : -2 ], gallery_augmented[ :, -1 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8faa1105c89f4c5398758b03626d9ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_rank_list = []\n",
    "\n",
    "# for i in range( 2,3 ):\n",
    "for i in tqdm_notebook( range( query_augmented.shape[ 0 ] ) ):\n",
    "\n",
    "    \n",
    "    query_label = query_augmented[ i, -1 ].astype( int )\n",
    "\n",
    "    # Test query point\n",
    "    X_test = query_augmented[ i ][ : -2 ].reshape( 1, -1 ) # Remove last 2 columns ( camId and label )\n",
    "    \n",
    "    distances, indices = KNN.kneighbors( X_test ) # Neighbours are ordered closest to furthest\n",
    "    \n",
    "    # Compare\n",
    "    distances = distances.flatten()\n",
    "    indices   = indices.flatten()\n",
    "    \n",
    "    removed_indices = []\n",
    "    \n",
    "    # Remove indices with same camId and Row\n",
    "    for ind in indices:\n",
    "        if( ~( gallery_augmented[ ind, -1 ] == query_label and \n",
    "           gallery_augmented[ ind, -2 ] == query_augmented[ i, -2 ].astype( int ) ) ):\n",
    "            \n",
    "            removed_indices.append( ind )\n",
    "    \n",
    "    removed_indices = np.asarray( removed_indices )\n",
    "            \n",
    "    \n",
    "    rank_list = [ gallery_augmented[ ind, -1 ].astype( int ) == query_label for ind in removed_indices[ : 10 ] ]\n",
    "    query_rank_list.append( rank_list )\n",
    "    \n",
    "query_rank_list = np.asarray( query_rank_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank@1: 45.92857142857143%\n",
      "rank@5: 66.57142857142857%\n",
      "rank@10: 74.78571428571429%\n"
     ]
    }
   ],
   "source": [
    "rankAt1  = query_rank_list.T[ 0 ]\n",
    "rankAt5  = query_rank_list.T[ : 5 ].T\n",
    "rankAt10 = query_rank_list.T[ : 10 ].T\n",
    "\n",
    "cmc1  = rankAt1\n",
    "cmc5  = np.sum( rankAt5, axis = 1 ) > 0 \n",
    "cmc10 = np.sum( rankAt10, axis = 1 ) > 0\n",
    "\n",
    "print( 'rank@1: {}%'.format( np.sum( cmc1 ) / cmc1.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@5: {}%'.format( np.sum( cmc5 ) / cmc5.shape[ 0 ] * 100 ) )\n",
    "print( 'rank@10: {}%'.format( np.sum( cmc10 ) / cmc10.shape[ 0 ] * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | rank@1 | rank@5 | rank@10 |\n",
    "| --- | --- | --- | --- |\n",
    "Baseline | 47.0% | 66.85714285714286% | 74.92857142857143%\n",
    "KPCA cosine ( 110 components )| 47.42857142857143% | 67.0% | 74.85714285714286%\n",
    "KPCA cosine 200 | 47.64285714285714% | 67.35714285714286% | 75.07142857142857%\n",
    "KPCA cosine 400 | 47.785714285714285% | 67.14285714285714% | 75.0%\n",
    "KPCA cosine 1000 | 47.35714285714286% | 67.14285714285714% | 75.07142857142857%\n",
    "NCA | 44.642857142857146% | 65.92857142857143% | 73.85714285714286%\n",
    "KPCA cosine ( 100 ) + NCA | 45.42857142857143 | 66.21428571428571 | 75.35714285714286\n",
    "kpca cosine 400 + NCA | 46.42857142857143% | 67.28571428571428% | 74.57142857142857%\n",
    "kpca cosine 1000 + NCA | 43.642857142857146% | 63.714285714285715% | 71.5%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
