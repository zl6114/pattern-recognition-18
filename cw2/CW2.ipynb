{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2\n",
    "\n",
    "## Load Data\n",
    "* File is 500mb, load once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (14096, 2048)\n"
     ]
    }
   ],
   "source": [
    "with open( \"PR_data/feature_data.json\", \"r\" ) as file:\n",
    "    features = json.load( file )\n",
    "    \n",
    "data = np.asarray( features )\n",
    "\n",
    "print( 'Data shape: {}'.format( data.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Annotations\n",
    "\n",
    "From the file **cuhk03_new_protocol_config_labeled.mat**\n",
    "\n",
    "There are 6 main components of this file:\n",
    "\n",
    "1. camId specidies whether image was taken from camera 1 or camera 2. While evaluating your algorithms, you should not consider images of your current query identity taken from the same camera. For example, when you create ranklist for the first query image (index 22, label 3, camera 1, name \"1_003_1_02.png\"), you should not include images with indexes 21, 23, 24 in this ranking list\n",
    "2. filelist\n",
    "3. gallery_idx, which specifies indexes of the part of the dataset from which you compose your ranklists during testing phase\n",
    "4. labels contains ground truths for each image\n",
    "5. query_idx contains indexes of query images\n",
    "6. train_idx contains indexes of images that can be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matfile\n",
    "mat = loadmat( 'PR_data/cuhk03_new_protocol_config_labeled.mat' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training indexes : (7368,)\n",
      "Loading test indexes : (1400,)\n"
     ]
    }
   ],
   "source": [
    "# Load labels\n",
    "labels = mat[ 'labels' ].flatten()\n",
    "\n",
    "# Load indexes\n",
    "train_idxs = mat[ 'train_idx' ].flatten()\n",
    "test_idxs  = mat[ 'query_idx' ].flatten()\n",
    "\n",
    "# Load training indexes\n",
    "print( \"Loading training indexes : {}\".format( train_idxs.shape ) )\n",
    "print( \"Loading test indexes : {}\".format( test_idxs.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (7368, 2048)\n",
      "Train Label : (7368,)\n",
      "\n",
      "Test Set : (1400, 2048)\n",
      "Test Label : (1400,)\n"
     ]
    }
   ],
   "source": [
    "# Create Train Set\n",
    "train_set   = []\n",
    "train_label = []\n",
    "\n",
    "for i in train_idxs:\n",
    "    train_set.append( data[ i - 1 ] )\n",
    "    train_label.append( labels[ i - 1 ] )\n",
    "    \n",
    "train_set   = np.asarray( train_set )\n",
    "train_label = np.asarray( train_label )\n",
    "\n",
    "print( 'Train Set : {}'.format( train_set.shape ) )\n",
    "print( 'Train Label : {}'.format( train_label.shape ) )\n",
    "\n",
    "\n",
    "# Create Test Set\n",
    "test_set   = []\n",
    "test_label = []\n",
    "\n",
    "for i in test_idxs:\n",
    "    test_set.append( data[ i - 1] )\n",
    "    test_label.append( labels[ i - 1 ] )\n",
    "    \n",
    "test_set   = np.asarray( test_set )\n",
    "test_label = np.asarray( test_label )\n",
    "\n",
    "print( '\\nTest Set : {}'.format( test_set.shape ) )\n",
    "print( 'Test Label : {}'.format( test_label.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load Data Set\n",
    "X = train_set\n",
    "Y = train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
